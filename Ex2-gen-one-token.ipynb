{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a47dbf70-b50a-43fe-94e3-8d3bb620c281",
   "metadata": {},
   "source": [
    "# 연습문제: 한 번에 하나의 토큰 생성하기\n",
    "\n",
    "이 연습에서는 LLM이 이전 토큰을 사용하여 다음 토큰을 예측하면서 한 번에 하나의 토큰씩 텍스트를 생성하는 방식을 이해하게 될 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c731d9-a5b5-4f71-9463-0952b17e3c1d",
   "metadata": {},
   "source": [
    "## 1단계. 토크나이저와 모델 로드하기\n",
    "\n",
    "먼저 HuggingFace의 transformers 라이브러리에서 토크나이저와 모델을 로드합니다. 토크나이저는 모델이 이해할 수 있는 숫자 목록으로 문자열을 분할하는 함수입니다.\n",
    "\n",
    "이 연습에서는 모든 코드가 여러분을 위해 작성될 것입니다. 여러분은 따라하기만 하면 됩니다!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46d0c56",
   "metadata": {},
   "source": [
    "### 설치해야 할 목록\n",
    "- python3.11 -m venv .venv\n",
    "- source .venv/bin/activate\n",
    "- pip install --upgrade pip\n",
    "- pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "- pip install transformers\n",
    "- pip install pandas\n",
    "- pip install IPython\n",
    "- pip install jupyterlab ipywidgets\n",
    "- jupyter lab build\n",
    "\n",
    "### 설치후 실행\n",
    "- jupyter lab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f618acdd-06a3-4d3c-981d-fb11632f97ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  52,   67, 4355,  318,  262, 1266, 1295,  284, 2193,  546, 1152,  876]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# To load a pretrained model and a tokenizer using HuggingFace, we only need two lines of code!\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
    "\n",
    "# We create a partial sentence and tokenize it.\n",
    "text = \"Udacity is the best place to learn about generative\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "# Show the tokens as numbers, i.e. \"input_ids\"\n",
    "inputs[\"input_ids\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66625be-e6eb-46af-988c-d313f3a24815",
   "metadata": {},
   "source": [
    "## 2단계. 토큰화 검토하기\n",
    "\n",
    "이 토큰들이 무엇을 의미하는지 살펴봅시다!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55d4c411-eb20-4e5f-a872-18536da50e97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tensor(52)</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tensor(67)</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tensor(4355)</td>\n",
       "      <td>acity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tensor(318)</td>\n",
       "      <td>is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tensor(262)</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tensor(1266)</td>\n",
       "      <td>best</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tensor(1295)</td>\n",
       "      <td>place</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tensor(284)</td>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tensor(2193)</td>\n",
       "      <td>learn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tensor(546)</td>\n",
       "      <td>about</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>tensor(1152)</td>\n",
       "      <td>gener</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>tensor(876)</td>\n",
       "      <td>ative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id   token\n",
       "0     tensor(52)       U\n",
       "1     tensor(67)       d\n",
       "2   tensor(4355)   acity\n",
       "3    tensor(318)      is\n",
       "4    tensor(262)     the\n",
       "5   tensor(1266)    best\n",
       "6   tensor(1295)   place\n",
       "7    tensor(284)      to\n",
       "8   tensor(2193)   learn\n",
       "9    tensor(546)   about\n",
       "10  tensor(1152)   gener\n",
       "11   tensor(876)   ative"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show how the sentence is tokenized\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def show_tokenization(inputs):\n",
    "    return pd.DataFrame(\n",
    "        [(id, tokenizer.decode(id)) for id in inputs[\"input_ids\"][0]],\n",
    "        columns=[\"id\", \"token\"],\n",
    "    )\n",
    "\n",
    "\n",
    "show_tokenization(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c1b5e1-ef04-4a11-9ed4-ce920564b2ef",
   "metadata": {},
   "source": [
    "### 서브워드 토큰화\n",
    "\n",
    "흥미로운 점은 이 경우 토큰이 단순히 글자도 아니고 단어도 아니라는 것입니다. 때로는 짧은 단어가 단일 토큰으로 표현되지만, 때로는 단일 토큰이 단어의 일부 또는 단일 글자를 나타냅니다. 이를 서브워드 토큰화라고 합니다.\n",
    "\n",
    "## 2단계. 다음 토큰의 확률 계산하기\n",
    "\n",
    "이제 PyTorch를 사용하여 이전 토큰이 주어졌을 때 다음 토큰의 확률을 계산해 보겠습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8bd74f6-a363-4aef-b9c9-113e7d569afc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>token</th>\n",
       "      <th>p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8300</th>\n",
       "      <td>8300</td>\n",
       "      <td>programming</td>\n",
       "      <td>0.157596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4673</th>\n",
       "      <td>4673</td>\n",
       "      <td>learning</td>\n",
       "      <td>0.148418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4981</th>\n",
       "      <td>4981</td>\n",
       "      <td>models</td>\n",
       "      <td>0.048506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17219</th>\n",
       "      <td>17219</td>\n",
       "      <td>biology</td>\n",
       "      <td>0.046482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16113</th>\n",
       "      <td>16113</td>\n",
       "      <td>algorithms</td>\n",
       "      <td>0.027796</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id         token         p\n",
       "8300    8300   programming  0.157596\n",
       "4673    4673      learning  0.148418\n",
       "4981    4981        models  0.048506\n",
       "17219  17219       biology  0.046482\n",
       "16113  16113    algorithms  0.027796"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the probabilities for the next token for all possible choices. We show the\n",
    "# top 5 choices and the corresponding words or subwords for these tokens.\n",
    "\n",
    "import torch\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits[:, -1, :]\n",
    "    probabilities = torch.nn.functional.softmax(logits[0], dim=-1)\n",
    "\n",
    "\n",
    "def show_next_token_choices(probabilities, top_n=5):\n",
    "    return pd.DataFrame(\n",
    "        [\n",
    "            (id, tokenizer.decode(id), p.item())\n",
    "            for id, p in enumerate(probabilities)\n",
    "            if p.item()\n",
    "        ],\n",
    "        columns=[\"id\", \"token\", \"p\"],\n",
    "    ).sort_values(\"p\", ascending=False)[:top_n]\n",
    "\n",
    "\n",
    "show_next_token_choices(probabilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf754b52-0841-4c07-9f65-e76edffed21c",
   "metadata": {},
   "source": [
    "흥미롭네요! 모델은 가장 가능성이 높은 다음 단어가 \"programming\"이고, 그 다음으로 \"learning\"이 뒤따른다고 생각합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f56c9d5-8b3e-4f66-bc05-4d2d85f02558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next token id: 8300\n",
      "Next token:  programming\n"
     ]
    }
   ],
   "source": [
    "# Obtain the token id for the most probable next token\n",
    "next_token_id = torch.argmax(probabilities).item()\n",
    "\n",
    "print(f\"Next token id: {next_token_id}\")\n",
    "print(f\"Next token: {tokenizer.decode(next_token_id)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "628ad7e1-9c6a-44a7-a170-22e548edfd68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Udacity is the best place to learn about generative programming'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We append the most likely token to the text.\n",
    "text = text + tokenizer.decode(8300)\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30d5f3e-0729-4d9d-821d-f70dc14eada1",
   "metadata": {},
   "source": [
    "## 3단계. 토큰을 더 생성하기\n",
    "\n",
    "다음 셀은 `text`를 가져와서 다음에 나올 가능성이 가장 높은 토큰을 표시하고, 가장 가능성이 높은 토큰을 text에 추가합니다. 셀을 반복해서 실행하여 작동 방식을 확인하세요!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c221cb21-d0a9-4f0e-889d-e28c0eab0e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Udacity is the best place to learn about generative programming\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Next token probabilities:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>token</th>\n",
       "      <th>p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>.</td>\n",
       "      <td>0.352234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>,</td>\n",
       "      <td>0.135988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>290</td>\n",
       "      <td>and</td>\n",
       "      <td>0.109375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>287</td>\n",
       "      <td>in</td>\n",
       "      <td>0.069531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8950</th>\n",
       "      <td>8950</td>\n",
       "      <td>languages</td>\n",
       "      <td>0.058290</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id       token         p\n",
       "13      13           .  0.352234\n",
       "11      11           ,  0.135988\n",
       "290    290         and  0.109375\n",
       "287    287          in  0.069531\n",
       "8950  8950   languages  0.058290"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Press ctrl + enter to run this cell again and again to see how the text is generated.\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Show the text\n",
    "print(text)\n",
    "\n",
    "# Convert to tokens\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "# Calculate the probabilities for the next token and show the top 5 choices\n",
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits[:, -1, :]\n",
    "    probabilities = torch.nn.functional.softmax(logits[0], dim=-1)\n",
    "\n",
    "display(Markdown(\"**Next token probabilities:**\"))\n",
    "display(show_next_token_choices(probabilities))\n",
    "\n",
    "# Choose the most likely token id and add it to the text\n",
    "next_token_id = torch.argmax(probabilities).item()\n",
    "text = text + tokenizer.decode(next_token_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c94599-172a-4945-acb1-6107e1397c8b",
   "metadata": {},
   "source": [
    "## Step 4. Use the `generate` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df9808b5-7305-4f4d-bba2-423970512e16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Once upon a time, generative models of the human brain were used to study the neural correlates of cognitive function. In the present study, we used a novel model of the human brain to investigate the neural correlates of cognitive function. We used a novel model of the human brain to investigate the neural correlates of cognitive function. We used a novel model of the human brain to investigate the neural correlates of cognitive function. We used a novel model of the human brain to investigate the neural correlates of cognitive function."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Start with some text and tokenize it\n",
    "text = \"Once upon a time, generative models\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "# Use the `generate` method to generate lots of text\n",
    "output = model.generate(**inputs, max_length=100, pad_token_id=tokenizer.eos_token_id)\n",
    "\n",
    "# Show the generated text\n",
    "display(Markdown(tokenizer.decode(output[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0ec2eb-c0f7-4f8e-918d-519a08dbd62e",
   "metadata": {},
   "source": [
    "옛날 옛적에 인간 두뇌의 생성 모델은 인지 기능의 신경 상관 관계를 연구하는 데 사용되었습니다. 본 연구에서는 인간 두뇌의 새로운 모델을 사용하여 인지 기능의 신경 상관 관계를 조사했습니다. 우리는 인간 두뇌의 새로운 모델을 사용하여 인지 기능의 신경 상관 관계를 조사했습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f82553c-318e-4f1c-a716-e52ba70f2ef3",
   "metadata": {},
   "source": [
    "### 흥미롭네요...\n",
    "\n",
    "GPT-2는 여러분이 사용 경험이 있을 수 있는 GPT-4와 같은 최신 모델만큼 정교하지 않다는 것을 알 수 있을 것입니다. 종종 스스로 반복하고 항상 말이 되는 것은 아닙니다. 하지만 영어처럼 보이는 텍스트를 생성할 수 있다는 것은 여전히 매우 인상적입니다.\n",
    "\n",
    "## 연습문제 완료를 축하합니다! 🎉\n",
    "\n",
    "스스로에게 박수를 보내세요. 그리고 휴식을 취하세요.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49b1dd4-2e5a-4042-b83c-2256672d79fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
