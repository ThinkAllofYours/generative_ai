{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT-2를 사용한 텍스트 생성 예제\n",
    "\n",
    "이 노트북은 Hugging Face의 Transformers 라이브러리를 사용하여 GPT-2 모델로 텍스트를 생성하는 방법을 보여줍니다.\n",
    "\n",
    "## 1. 필요한 라이브러리 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 유틸리티 함수 정의\n",
    "\n",
    "토큰화 결과와 다음 토큰 예측 확률을 시각화하기 위한 함수들을 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_tokenization(inputs, tokenizer):\n",
    "    \"\"\"토큰화된 결과를 데이터프레임 형태로 보여주는 함수\n",
    "    Args:\n",
    "        inputs: 토큰화된 입력값\n",
    "        tokenizer: 사용중인 토크나이저\n",
    "    Returns:\n",
    "        DataFrame: 토큰 ID와 해당하는 실제 토큰을 보여주는 데이터프레임\n",
    "    \"\"\"\n",
    "    return pd.DataFrame(\n",
    "        [(id, tokenizer.decode(id)) for id in inputs[\"input_ids\"][0]],\n",
    "        columns=[\"id\", \"token\"],\n",
    "    )\n",
    "\n",
    "def show_next_token_choices(probabilities, tokenizer, top_n=5):\n",
    "    \"\"\"다음 토큰의 확률 분포를 보여주는 함수\n",
    "    Args:\n",
    "        probabilities: 각 토큰별 확률값\n",
    "        tokenizer: 사용중인 토크나이저\n",
    "        top_n: 상위 몇 개의 확률을 보여줄지 지정\n",
    "    Returns:\n",
    "        DataFrame: 상위 n개의 토큰과 그 확률을 보여주는 데이터프레임\n",
    "    \"\"\"\n",
    "    return pd.DataFrame(\n",
    "        [\n",
    "            (id, tokenizer.decode(id), p.item())\n",
    "            for id, p in enumerate(probabilities)\n",
    "            if p.item()\n",
    "        ],\n",
    "        columns=[\"id\", \"token\", \"p\"],\n",
    "    ).sort_values(\"p\", ascending=False)[:top_n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 모델과 토크나이저 로드\n",
    "\n",
    "GPT-2 모델과 토크나이저를 Hugging Face 모델 허브에서 로드합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델과 토크나이저를 로딩중...\n"
     ]
    }
   ],
   "source": [
    "print(\"모델과 토크나이저를 로딩중...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 텍스트 토큰화 및 다음 토큰 예측\n",
    "\n",
    "입력 텍스트를 토큰화하고 다음에 올 토큰을 예측해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "초기 텍스트: What is the best way to learn about generative\n",
      "\n",
      "토큰화 결과:\n",
      "             id   token\n",
      "0  tensor(2061)    What\n",
      "1   tensor(318)      is\n",
      "2   tensor(262)     the\n",
      "3  tensor(1266)    best\n",
      "4   tensor(835)     way\n",
      "5   tensor(284)      to\n",
      "6  tensor(2193)   learn\n",
      "7   tensor(546)   about\n",
      "8  tensor(1152)   gener\n",
      "9   tensor(876)   ative\n"
     ]
    }
   ],
   "source": [
    "# 초기 텍스트 설정\n",
    "text = \"What is the best way to learn about generative\"\n",
    "print(\"초기 텍스트:\", text)\n",
    "\n",
    "# 텍스트 토큰화\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "# 토큰화 결과 출력\n",
    "print(\"\\n토큰화 결과:\")\n",
    "print(show_tokenization(inputs, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 다음 토큰 예측 확률 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "다음 토큰 예측 중...\n",
      "\n",
      "다음 토큰 상위 5개 선택지:\n",
      "          id         token         p\n",
      "4673    4673      learning  0.190161\n",
      "8300    8300   programming  0.166931\n",
      "17219  17219       biology  0.075311\n",
      "4981    4981        models  0.055784\n",
      "16113  16113    algorithms  0.043036\n",
      "\n",
      "선택된 다음 토큰 ID: 4673\n",
      "선택된 다음 토큰:  learning\n"
     ]
    }
   ],
   "source": [
    "print(\"다음 토큰 예측 중...\")\n",
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits[:, -1, :]\n",
    "    probabilities = torch.nn.functional.softmax(logits[0], dim=-1)\n",
    "\n",
    "# 상위 5개 토큰 선택지 출력\n",
    "print(\"\\n다음 토큰 상위 5개 선택지:\")\n",
    "print(show_next_token_choices(probabilities, tokenizer))\n",
    "\n",
    "# 가장 확률이 높은 토큰 선택 및 텍스트에 추가\n",
    "next_token_id = torch.argmax(probabilities).item()\n",
    "print(f\"\\n선택된 다음 토큰 ID: {next_token_id}\")\n",
    "print(f\"선택된 다음 토큰: {tokenizer.decode(next_token_id)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 전체 문장 생성\n",
    "\n",
    "이번에는 `generate` 메서드를 사용하여 더 긴 텍스트를 생성해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "생성된 텍스트:\n",
      "What is the best way to learn about generative learning?\n",
      "\n",
      "The best way to learn about generative learning is to learn about the generative learning process.\n",
      "\n",
      "The generative learning process is a process that involves learning about the generative learning process.\n",
      "\n",
      "The generative learning process is a process that involves learning about the generative learning process.\n",
      "\n",
      "The generative learning process is a process that involves learning about the generative learning process.\n",
      "\n",
      "The generative learning process\n"
     ]
    }
   ],
   "source": [
    "# 새로운 초기 텍스트로 시작\n",
    "initial_text = \"What is the best way to learn about generative\"\n",
    "inputs = tokenizer(initial_text, return_tensors=\"pt\")\n",
    "\n",
    "# generate 메소드를 사용하여 텍스트 생성\n",
    "output = model.generate(\n",
    "    **inputs,\n",
    "    max_length=100,\n",
    "    pad_token_id=tokenizer.eos_token_id\n",
    ")\n",
    "\n",
    "# 생성된 텍스트 출력\n",
    "generated_text = tokenizer.decode(output[0])\n",
    "print(\"\\n생성된 텍스트:\")\n",
    "print(generated_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
